# Devloped Handwritten Text Recognition Data Generator toolkit 

A synthetic data generator for text recognition task modfied for Hungarain languge by adding new fonts that support Hungarain special characters 

## What is it for?

Generating text image samples to train an HTR and/or OCR software. Here you can find a nice [the official documentation](https://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html).

## How to use it ?
Make new virtual environment using `python` 
```
!pip install virtualenv
!mkdir HuTRDG
!cd HuTRDG
!python3.8 -m venv env
```
Active Virtual Environment 
`
source env/bin/activate
`
Install the pypi package

```
!pip install trdg
```
## Devloping the existing tool for new languge you need : 
Afterwards, you can use `trdg` from the CLI. I recommend using a `virtualenv` instead of installing with `sudo`.

If you want to add another language, you can clone the repository instead. Simply run `pip install -r requirements.txt`
```
!git clone https://github.com/Mohammed20201991/OCR_HU_Tra2022.git
!cd HuTRDG
```

## Docker Image

If you would rather not have to install anything to use TextRecognitionDataGenerator, you can pull the docker image. Done by `Belval`

```
docker pull belval/trdg:latest

docker run -v /output/path/:/app/out/ -t belval/trdg:latest trdg [args]
```

The path (`/output/path/`) must be absolute.

## How does it work?

Words will be randomly chosen from a dictionary of a specific language. Then an image of those words will be generated by using font, background, and modifications (skewing, blurring, etc.) as specified.

### Basic (Python module)

The usage as a Python module is very similar to the CLI, but it is more flexible if you want to include it directly in your training pipeline, and will consume less space and memory. There are 4 generators that can be used.

```py
from trdg.generators import (
    GeneratorFromDict,
    GeneratorFromRandom,
    GeneratorFromStrings,
    GeneratorFromWikipedia,
)

# The generators use the same arguments as the CLI, only as parameters
generator = GeneratorFromStrings(
    ['Test1', 'Test2', 'Test3'],
    blur=2,
    random_blur=True
)

for img, lbl in generator:
    # Do something with the pillow images here.
```

You can see the full class definition here:

- [`GeneratorFromDict`](trdg/generators/from_dict.py)
- [`GeneratorFromRandom`](trdg/generators/from_random.py)
- [`GeneratorFromStrings`](trdg/generators/from_strings.py)
- [`GeneratorFromWikipedia`](trdg/generators/from_wikipedia.py)

### Using (CLI)

`trdg -c 100 -w 5 -f 64`

You get 100 randomly generated images with random text on them like:

![1](samples/48.jpg "1")
![2](samples/138.jpg "2")
![3](samples/194.jpg "3")
![4](samples/445.jpg "4")
![5](samples/1283.jpg "5")
![6](samples/1347.jpg "6")
![7](samples/100006.jpg "7")
![8](samples/100018.jpg "8")
![9](samples/v7_2.jpg "9")
![10](samples/words_dict_498.jpg "10")
![11](samples/words_dict_239.jpg "11")

By default, they will be generated to `out/` in the current working directory.

### Testing (using python)
The command that used to prepare test image (ground truth) . <br>
`python3 run.py -c 1  -w 11 -i texts/hu_test.txt --name_format 0  --output_dir "out3/" -f 64 --thread_count 8 --font_dir fonts/hu_test/ `
To test uints :
```
!cd TextRecognitionDataGeneratorHuMu23
!python3 tests.py
```

### Handwritten

Our task is handwritten for Hungarain Languge maybe you are working on an OCR for handwritten text? Add `-hw`! (Experimental). And I leave this step for futuer the models [this excellent project](https://github.com/Grzego/handwriting-generation) by Grzego was developed by a Tensorflow model trained using English data soe for Hungarain we need to train it on Hungarain texts.

**The project does not require TensorFlow to run if you aren't using this feature**

### Dictionary

The text is chosen at random in a dictionary file (that can be found in the *dicts* folder) and drawn on a white background made with Gaussian noise. The resulting image is saved as [text]\_[index].jpg

There are a lot of parameters that you can tune to get the results you want, therefore checking out `trdg -h` for more information.

## Create images with Hungarain text

It is simple! Just do `trdg -l hu -c 1000 -w 5`!

Generated texts come both in simplified and traditional Hungarain scripts.

Traditional:

![30](samples/30.jpg "0")

Simplified:

![31](samples/31.jpg "1")

## Add new fonts
The list for added new fonts for both Hungarain and English could be found [Fonts list](https://github.com/Mohammed20201991/OCR_HU_Tra2022/blob/main/HuTRDG/doc/fonts_testing.pdf)
The script picks a font at random from the *fonts* directory.

| Directory | Languages |
|:-----|:-----|
| fonts/latin | English, French, Spanish, German |
| fonts/hu    | Hungarian |

Simply add/remove fonts until you get the desired output.

If you want to add a new non-latin language, the amount of work is minimal.

1. Create a new folder with your language [two-letters code](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
2. Add a .ttf font in it
3. Edit `run.py` to add an if statement in `load_fonts()`
4. Add a text file in `dicts` with the same two-letters code
5. Run the tool as you normally would but add `-l` with your two-letters code

It only supports .ttf for now.
### For fonts testing:
This test is important when you have new fonts to see if all alph ,letters and symbols are recognized well especialy for Hungarian special char.
got to [fonts_testing.py](https://github.com/Mohammed20201991/OCR_HU_Tra2022/blob/main/HuTRDG/trdg/fonts_testing.py)  script and run: 
```
python3 fonts_testing.py
```

## Benchmarks

Number of images generated per second.

- Intel Core i7-4710HQ @ 2.50Ghz + SSD (-c 1000 -w 1)
    - `-t 1` : 363 img/s
    - `-t 2` : 694 img/s
    - `-t 4` : 1300 img/s
    - `-t 8` : 1500 img/s
- AMD Ryzen 7 1700 @ 4.0Ghz + SSD (-c 1000 -w 1)
    - `-t 1` : 558 img/s
    - `-t 2` : 1045 img/s
    - `-t 4` : 2107 img/s
    - `-t 8` : 3297 img/s
  - NVIDIA A100 Tensor Core GPU Provided by [National Hungarain Laboratory For Digital Heritage](https://dh-lab.hu/en/kezdolap-english/)

## Contributing
If someone wanna add his/her contribution look what is left
1. Fine-tune [handwriting-generation models](https://github.com/Grzego/handwriting-generation) done by Grzego on Hungarain data.
2. Create a pull request

## Generated data:
This data is private upon request only for Academic research 
<ul dir="auto">
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v1_1">lines_hu_v1_1</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v2">lines_hu_v2</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v2_1">lines_hu_v2_1</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v3">lines_hu_v3</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v4">lines_hu_v4</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v5">lines_hu_v5</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v6">lines_hu_v6</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/lines_hu_v7">lines_hu_v7</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/HungarianNames">HungarianNames</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/words_hu_dict">words_hu_dict</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/En_Words_Dict">En_Words_Dict</a></li>
<li><a href="https://huggingface.co/datasets/AlhitawiMohammed22/En_Brown_lines">En_Brown_lines</a></li>
</ul>

## Commands were used during data generation: 
- hu_liness_v1

`python3 run.py -i "texts/Out_split_1/split_1.txt"  -w 9 -t 8 -f 64 -l hu -c 500001  -na 2 --output_dir "out/lines/hu/" --font_dir fonts/hu/ -b 3 -al 0`

- hu_lines_v3

`python3 run.py -c 15 -l hu -w 8 -i texts/Out_split_1/split_24.txt --name_format 2 --output_dir "out/hu/lines/3/" -f 64 --thread_count 8 --font_dir fonts/hu/ -k 1 -rbl -al 1 -tc '#000000,#888888' -bl 1 -b 3 -d 3`

- hu_lines_v4

` python3 run.py -c ?? -l hu -w 8 -i texts/Out_split_1/split_16.txt --name_format 2 --output_dir "out/hu/lines/4/" -f 64 --thread_count 8 --font_dir fonts/hu/ -k 1 -rbl -al 1 -tc '#000000,#888888' -bl 1 -b 3 -d 3 `

- hu_lines_v5

` python3 run.py -c 50000 -l hu -w 8 -i texts/split_3.txt --name_format 2 --output_dir "out/testPrintedFonts/" -f 64 --thread_count 8 --font_dir fonts/hu_printed/ -d 2 -k 1 -rk -b 1
`

- hu_lines_v7

`python3 run.py -c 100000 -l hu -w 8 -i texts/split_4.txt --name_format 2 --output_dir "out/v7/" -f 64 --thread_count 8 --font_dir fonts/hu_printed/ -b 3`

- HungarainNmes

`python3 run.py -c 4478 -l hu -i texts/Hungarain_NAMES.txt --name_format 2 --output_dir "out/hu/Names/" -f 64 --thread_count 8 --font_dir "fonts/hu/"`

- words_hu_dict

`python3 run.py -i "dicts/hu.txt"  -t 8 -f 64 -l hu -c 60345  -na 2 --output_dir "out/words/hu/" --font_dir fonts/hu/ -b 3 -al 0`

- En_words_dict

`python3 run.py -i "dicts/en.txt"  -t 8 -f 64 -l en -c 466479  -na 2 --output_dir "out/words/en/" --font_dir fonts/hu/ -b 3 -al 0`

- En_brown_lines_v1

`python3 run.py  -l en -c 19950  --name_format 2 -i "texts/Brown/split_1.txt" --output_dir "out/en/Brown/1/" -f 64 --thread_count 8  -k 1  -rk  -rbl -b -bl 1  -al 0 -cs 0  --font_dir fonts/en/`

- En_brown_lines_v2

`python3 run.py  -l en -c 18845  --name_format 2 -i "texts/Brown/split_2.txt" --output_dir "out/en/Brown/2/" -f 64 --thread_count 8  --font_dir fonts/en/`

- En_brown_lines_v3

`python3 run.py -c 19850 -l en -w 14 -i "texts/Brown/split_3.txt"  --name_format 2 --output_dir "brown_en_v3/images/" -f 64 --thread_count 8 --font_dir fonts/en/ -k 3 -d 1  -rk -rbl -bl 2 -al 0 -cs 0  -tc '#000000,#888888'`

- En_brown_lines_v4

`python3 run.py -c 19950  -l en -w 11 -i "texts/Brown/split_4.txt" --name_format 2 --output_dir "/brown_en_v4/images/" -f 64 --thread_count 8 --font_dir fonts/en/ -k 1 -d 2`

### Acknowledgment: 
This work has been done using the infrastructure of the ELTE University Researcher, Under the supervision of:

**Gyöngyössy Natabara Máté** , Email: natabara@inf.elte.hu

## References:
<ul dir="auto">
<li><a href="https://github.com/Belval/TextRecognitionDataGenerator">TextRecognitionDataGenerator</a></li>
<li><a href="https://github.com/Grzego/handwriting-generation">Handwriting-Generation using Deep Learning methods</a></li>
<li><a href="https://github.com/Mohammed20201991/TextRecognitionDataGeneratorHuMu23">Devloped Text Recognition Data Generator for Hungarain Languge</a></li>
<li><a href="https://data.statmt.org/cc-100/">hu.txt.xz</a></li>
<li><a href="http://www.sls.hawaii.edu/bley-vroman/brown_corpus.html">Brown Corpus</a></li>    
</ul>

## Contact
Email: Mohamedabid092@gmail.com
