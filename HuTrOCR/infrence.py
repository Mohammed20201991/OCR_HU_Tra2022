import argparse
from PIL import Image
from transformers import TrOCRProcessor ,VisionEncoderDecoderModel
import gradio as gr
from PIL import Image

parser = argparse.ArgumentParser( description="Example script for Inference on unseen data using our trained and fine-tunned models.",
                                  formatter_class=argparse.ArgumentDefaultsHelpFormatter
                                )
parser.add_argument("--processor_dir", type=str, default='AlhitawiMohammed22/trocr_large_lines_v2_1_ft_on_dh-lab')
parser.add_argument("--ft_model_id", type=str, default='AlhitawiMohammed22/trocr_large_lines_v2_1_ft_on_dh-lab')
parser.add_argument("--working_dir", type=str, default='/home/ngyongyossy/mohammad/Data/DH-Lab_lines/images/')
parser.add_argument("--save_imgs_dir", type=str, default='./images/infer_imgs/')
parser.add_argument("--lang", type= str, default= 'Hu')
args = parser.parse_args()

# English model 
if args.lang =='En':
    processor = TrOCRProcessor.from_pretrained(args.processor_dir)
    model = VisionEncoderDecoderModel.from_pretrained(args.ft_model_id)

# Hungarain Model 
else:
    processor = TrOCRProcessor.from_pretrained(args.processor_dir)
    model = VisionEncoderDecoderModel.from_pretrained(args.ft_model_id)

# load image examples from the Hungarain database
urls = ['RALK987_1865_817_123_002-029.jpg',
        'RALK987_1865_817_120_001-009.jpg',
        'RALK987_1865_817_250_001-007.jpg',
        'RALK987_1865_817_297_003-029.jpg',
        'RALK987_1865_817_296_001-014.jpg',
       ]

for idx, url in enumerate(urls):
  image = Image.open(f'{args.working_dir}{url}')
  image.save(f"{args.save_imgs_dir}image_{idx}.png")

def process_image(image):
    '''
    Function that recive an image processed at first step extract featuers in pixle values and then return text generated by languge model
    '''
    # prepare image
    pixel_values = processor(image, return_tensors="pt").pixel_values
    # generate (no beam search)
    generated_ids = model.generate(pixel_values,pad_token_id=processor.tokenizer.eos_token_id)
    # decode 
    return processor.batch_decode(generated_ids, skip_special_tokens=True)[0] # generated_text

title = "Interactive Demo: HuTrOCR"
description = "Demo for Hungarain TrOCR, The benchmark dataset here is (DH-Lab (Arany200) : 3.681 % CER, 16.189% WER) an encoder-decoder model consisting of an image Transformer encoder and a text Transformer decoder for state-of-the-art Optical Character Recognition (OCR) on single-text line images. This particular model is pre-trained on Synthestic data and then fine-tuned on Hungarrain,a dataset of annotated handwritten images. To use it, simply upload an image or use the example image below and click 'submit'. Results will show up in a few seconds. \n after you get Prediction value as text you can measuer How much the <a href='https://huggingface.co/spaces/AlhitawiMohammed22/CER_Hu-Evaluation-Metrics'> CER Evaluation Metrics</a> "
article = "<p style='text-align: center'> <a href='https://github.com/Mohammed20201991/OCR_HU_Tra2022'> OCR_HU_Tra2022 </a></p>"
all_wrights="<p style='color: red; font-size: 20px;'>Auther: Al-Hitawi Mohammed</p>"
examples =[[f"{args.save_imgs_dir}image_0.png"], 
           [f"{args.save_imgs_dir}image_1.png"], 
           [f"{args.save_imgs_dir}image_2.png"],
           [f"{args.save_imgs_dir}image_3.png"],
           [f"{args.save_imgs_dir}image_4.png"],
          ]

iface = gr.Interface(fn=process_image, 
                     inputs=gr.inputs.Image(type="pil"), 
                     outputs=gr.outputs.Textbox(),
                     title=title,
                     description=description,
                     article=article,
                     examples=examples)
iface.launch(debug=True,share=True)   #,debug=False

# Partially Correct Prediction    CER= 0.085
# {"file_name": "RALK987_1865_817_123_002-029.jpg", 
# "text":   "Akadémia tiszteletteljes bizalommal"}
# Pred.==>   Akadémia tiszteletteljes bizalom 

# Totally Correct Prediction      CER= 0.0  
# {"file_name": "RALK987_1865_817_120_001-009.jpg", 
# "text":  "és Drágfi János törvényesített"}
# Pred.==>  és Drágfi János törvényesített

# Partially Correct Prediction      CER= 0.039
# {"file_name": "RALK987_1865_817_250_001-007.jpg", 
# "text": "ha szükséges 19-dik napjain, délutáni 5 órakor, nag"}
# Pred.==> ha szükséges 19-dik napjain, délutáni s órakor, nagy 


# Partially Correct Prediction   CER= 0.044 
# {"file_name": "RALK987_1865_817_297_003-029.jpg", 
# "text": "bátor vagyok kérdésbe tenni, hogy jár-e ezek-"} 
# Pred.==> bátor vagyok kérdésbe tenni, hogy jár-e ezt-  

# Partially Correct Prediction   CER= 0.145 
# {"file_name": "RALK987_1865_817_296_001-014.jpg", 
# "text": "és Pólya József r. tagoknak adatott, ki birálat végett."}
# Pred.==> és Pólya főzsef rajoknak adatott ki birálat végett,



# Other test samples Syn and new wrote (demo by upload via image Thesis Demo Dir )
# CER= 0.109 
# {"file_name": "test_image.jpeg", 
# "text":   "Ebben a projektben a magyar nyelv Kézirásos elismerését vegezzük"}
# Predicted: Ehhezt a projek-ben a magyar nyelv Kézirásos elismerését végezzik

# CER= 0.0  
# {"file_name": "v7_34312.jpg", 
# "text":   "étel és a víz egyaránt teljesen hasznosul a morontia"}
# Predicted: étel és a víz egyaránt teljesen hasznosul a morontia

# CER = 0.018  IT SHOULD BE 0.0 !!! this is surprise fact 
# {"file_name": "353122.jpg", 
# "text":   "alkalmazni; e az elintézett ügyek iratait — az irattári"}
# Predicted: alkalmazni; e az elintézett ügyek iratait – az irattári

# CER: 0.0 
# {"file_name":"lines_hu_v1_429786.jpg",
# "text":    "politikai öntudatú valóságvilágot. Ez már a közös veszély rémképe"}
# Prediction: politikai öntudatú valóságvilágot. Ez már a közös veszély rémképe

# If we dont want to use Gradio 
# Calling the processor is equivalent to calling the feature extractor
# pixel_values = processor(image, return_tensors="pt").pixel_values
# print(pixel_values.shape)

# generated_ids = model.generate(pixel_values,max_length= 64)
# generated_text = processor.batch_decode(generated_ids, skip_special_tokens= False)[0]
# print(generated_text)